{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for reactions addition allowing growth on uncommon substrates \n",
    "\n",
    "Once the models have been loaded and prepared (*see Tutorial 1*) the analysis can be performed. The pipeline first conisders if the model is able to grow on the user-indicated carbon source and if not it looks for which reactions from the universal model could be added to the model of the chassis organism in order to confer that function to it.\n",
    "\n",
    "This first search of reactions allowing growth on an uncommon substrate is done with the function *analysis_gf_sol*. This function sets the right constraint in the model of the chassis and then calls the COBRApy[1] function for [gapfilling analysis](https://cobrapy.readthedocs.io/en/latest/gapfilling.html). In particular, *analysis_gf_sol* sets the upper bound of the biomass reactions to the normal growth rate in the wild type chassis. Thus, any reaction addition that is identified with gap-filling leads to a growth rate that is maximally equal to the wild type. (The objective of the optimization is the biomass reaction)\n",
    "\n",
    "The function *dict_prod_sol* is used to evaluate if the addition of the reactions indicated by the gapfilling analysis makes the chassis' model also able to produce a target product indicate by the user. If the model can't already simulate production the function *dict_prod_sol* calls again the COBRApy[1] function for [gapfilling analysis](https://cobrapy.readthedocs.io/en/latest/gapfilling.html).\n",
    "\n",
    "Checking the model's ability to produce the target compound requires a different model objective and additional constraints. The objective of the optimization is set to be the exchange reaction of the target. The biomass reaction has to be constrained in the lower bound, to indicate the model that the optimization of the formation of the target should still allow growth, otherwise the simulation will maximize production leading to 0 1/h growth rate, which is not realistic. Additionally, the uptake of the substrate is constrained by setting a minium lower value that can be indicated by the user if the ammount of substrate in the medium can be estimated. \n",
    "\n",
    "If the consumption of a compound in the medium is the only optimization of interest, an intermediate of the degradation pathway should be indicated anyway in order to be able to use the other functions of the pipeline (including the one needed to score the options). This is due to the fact that the functions downstream to *analysis_gf_sol* build upon the output of this function, hence *dict_prod_sol* uses the output of *analysis_gf_sol* as argument, while the output of both previous function is used by *cons_prod_dict* to generate a final object comprehensive of all the information gathered previously and calls the thermodynamic analysis too. This final output is used among others by *scores_evaluations* to score the several alternative reaction addition and the fluxes of substrate uptake and product formation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import statemets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "\n",
    "from pipeline.scripts.import_models import get_universal_main, get_reference_model\n",
    "from pipeline.scripts.input_parser import main\n",
    "from pipeline.scripts.analysis import analysis_gf_sol, dict_prod_sol, cons_prod_dict\n",
    "from pipeline.scripts.import_models import get_universal_main, get_reference_model\n",
    "from pipeline.scripts.input_parser import main\n",
    "from pipeline.scripts.scoring_system import (scores_evaluations, score_BB_presence, \n",
    "                            plotting_KI_BB_scores)\n",
    "from pipeline.scripts.to_and_from_biobrick_wikidata import (output_for_biobrick_search, \\\n",
    "                                        run_harmonization_per_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file C:\\Users\\delip\\gurobi.lic\n",
      "Academic license - for non-commercial use only\n"
     ]
    }
   ],
   "source": [
    "data_repo = \"./pipeline/inputs\"\n",
    "model = get_reference_model(data_repo, './pipeline/inputs/ecoli_tutorial2.csv')\n",
    "universal = get_universal_main(data_repo, './pipeline/inputs/ecoli_tutorial2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For ch4 there isn't any uptake trasnsporter in the reference model\n",
      "The trasporter has been added to the \n",
      "                                reference model from the input file\n",
      "For nh4 there isn't any uptake trasnsporter in the reference model\n",
      "For for there isn't any uptake trasnsporter in the reference model\n",
      "\n",
      "The following reactions will be added to the universal model: ['R01142', 'R01143', 'MMO1', 'MMO2']\n",
      "unknown metabolite 'ch4_c' created\n",
      "unknown metabolite 'focytcc_c' created\n",
      "unknown metabolite 'ficytcc_c' created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iML1515</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x017160e00390</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>1877</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>2713</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>1.0*BIOMASS_Ec_iML1515_core_75p37M - 1.0*BIOMASS_Ec_iML1515_core_75p37M_reverse_35685</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>cytosol, extracellular space, periplasm</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iML1515 at 0x17160e00390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main('./pipeline/inputs/ecoli_tutorial2.csv', universal, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printed output above can be unserstood better looking at the example input file *ecoli_tutorial2.csv* that can be found in the inputs directory. \n",
    " \n",
    "* There is not transporter of methane in E. coli model iML1515. Thus, the pipeline adds the reaction included in the input file \n",
    "* Formate, intermediate product of methane oxidation is indicated as target\n",
    "* ALCD1 reaction (methanole dehydrogenase) is already in the model, so the pipeline recognize it and does not add it to the universal\n",
    "* There are no methane oxidizing reactions in the BiGG database, therefore the pipeline adds them to the universal reaction model.\n",
    "\n",
    "![input_main](./formate.png)\n",
    "\n",
    "\n",
    "## Running the analysis for making the model able to grow on the indicated substrate\n",
    "\n",
    "In this case the objective is to have an *E. coli* strain able to grow on methane. The chassis can't naturally grow on methane, therefore it is expected that the pipeline will use gapfilling to serach for additional reactions. The search can take few hours, depending on the PC, the number of iteration and the type of reactions needed. For this analysis on a Windows AMD64 processor running the pipeline via Jupyter notebook it takes apporximately 4 hours.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old biomass (objective) bounds =  (0.0, 1000.0)\n",
      "EX_pi_e pi_e <=>  -0.8459567750194139 \n",
      "\n",
      "EX_glc__D_e glc__D_e <=>  -10.0 \n",
      "\n",
      "EX_nh4_e nh4_e <=>  -9.471495371047927 \n",
      "\n",
      "EX_o2_e o2_e <=>  -22.131763238945897 \n",
      "\n",
      "New biomass (objective) bounds =  (0.0, 0.8769972144269785)\n",
      "\n",
      "ch4 is in the medium \n",
      "\n",
      "Exchange ch4:  ch4_e -->  Old bounds:  (0.0, 1000.0)\n",
      "Exchange ch4:  ch4_e <--  New bounds:  (-1000, 0)\n",
      "\n",
      "nh4 is in the medium \n",
      "\n",
      "Exchange nh4:  nh4_e <=>  Old bounds:  (-1000.0, 1000.0)\n",
      "Exchange nh4:  nh4_e <--  New bounds:  (-1000, 0)\n",
      "\n",
      "for is in the medium \n",
      "\n",
      "Exchange for:  for_e -->  Old bounds:  (0.0, 1000.0)\n",
      "Exchange for:  for_e -->  New bounds:  (0, 1000)\n",
      "Starting reaction search with GapFilling . . .\n",
      "\n",
      "---Model 1---\n",
      "\n",
      "Reaction ALCD1, solution of round 1 has been added to the model\n",
      "\n",
      "Reaction R01143, solution of round 1 has been added to the model\n",
      "\n",
      "Growth rate:  0.8769972144269785\n",
      "\n",
      "The flux throughr EX_ch4_e is:  -132.29724273917816\n",
      "\n",
      "The flux throughr EX_nh4_e is:  -9.47149537104829\n",
      "\n",
      "The flux throughr EX_for_e is:  0.0\n",
      "\n",
      "The flux throughr ALCD1 is:  132.2972444931726\n",
      "\n",
      "The flux throughr R01143 is:  132.29724273917816\n",
      "\n",
      "---Model 2---\n",
      "\n",
      "Reaction ALCD1, solution of round 2 has been added to the model\n",
      "\n",
      "Reaction MMO2, solution of round 2 has been added to the model\n",
      "\n",
      "Growth rate:  0.8769972144269785\n",
      "\n",
      "The flux throughr EX_ch4_e is:  -88.16265443063246\n",
      "\n",
      "The flux throughr EX_nh4_e is:  -9.471495371048178\n",
      "\n",
      "The flux throughr EX_for_e is:  0.0\n",
      "\n",
      "The flux throughr ALCD1 is:  88.16265618462688\n",
      "\n",
      "The flux throughr MMO2 is:  88.16265443063246\n",
      "\n",
      "---Model 3---\n",
      "\n",
      "Reaction POX2, solution of round 3 has been added to the model\n",
      "\n",
      "Reaction PRDX, solution of round 3 has been added to the model\n",
      "\n",
      "Reaction R01142, solution of round 3 has been added to the model\n",
      "\n",
      "Growth rate:  0.07906382561251472\n",
      "\n",
      "The flux throughr EX_ch4_e is:  -500.578829073911\n",
      "\n",
      "The flux throughr EX_nh4_e is:  -0.8538825961899411\n",
      "\n",
      "The flux throughr EX_for_e is:  0.0\n",
      "\n",
      "The flux throughr POX2 is:  6.828205063202287\n",
      "\n",
      "The flux throughr PRDX is:  500.57882923203863\n",
      "\n",
      "The flux throughr R01142 is:  500.578829073911\n",
      "\n",
      "---Model 4---\n",
      "\n",
      "Reaction ALCD1, solution of round 4 has been added to the model\n",
      "\n",
      "Reaction MMO2, solution of round 4 has been added to the model\n",
      "\n",
      "Growth rate:  0.8769972144269785\n",
      "\n",
      "The flux throughr EX_ch4_e is:  -88.16265443063246\n",
      "\n",
      "The flux throughr EX_nh4_e is:  -9.471495371048178\n",
      "\n",
      "The flux throughr EX_for_e is:  0.0\n",
      "\n",
      "The flux throughr ALCD1 is:  88.16265618462688\n",
      "\n",
      "The flux throughr MMO2 is:  88.16265443063246\n"
     ]
    }
   ],
   "source": [
    "consumption = analysis_gf_sol('./pipeline/inputs/ecoli_tutorial2.csv', model, universal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the printed output\n",
    "\n",
    "The output reports several information relative to the set up of the analysis as introduced above (e.g. constraints) and the results of the analysis with gapfilling. In order from top to bottom you can find the following information:\n",
    "\n",
    "- The biomass upper bound to the growth rate of the wild type (0.87 1/h)\n",
    "- Indication of the fluxes of the compounds that are take up from the mediume by the wild type strain\n",
    "- The old and new bounds of the exchange reaction of the compounds indicated by the user \n",
    "- The result of the analysis start after the indication that GapFilling algorithm is being run.  \n",
    "- The analysis of gapfilling can be run in several iteration (each one looking for reactions that if added satisfy the model's objective, growth in this case). The result of each iteration starts with a number. \n",
    "\n",
    "This function also generate an intermediate .csv file that can be found in the pipeline/outputs folder. It is advicable to rename the file before running *analysis_gf_sol* further, otherwise it get overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bounds of biomass during optimization of consumption =  (0.0, 0.8769972144269785)\n",
      "\n",
      "Bounds of biomass during optimization of production =  (0.04384986072134892, 0.8769972144269785)\n",
      "\n",
      "The metabs to produce are:  ['for']\n",
      "\n",
      "---1---\n",
      "The model can already satisfy the objective\n",
      "\n",
      "---2---\n",
      "The model can already satisfy the objective\n",
      "\n",
      "---3---\n"
     ]
    }
   ],
   "source": [
    "production = dict_prod_sol('./pipeline/inputs/ecoli_tutorial2.csv', consumption, model, universal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the printed output\n",
    "\n",
    "since the model can already produce formate, gapfilling analysis is not run and thus the analysis is way faster and the production rates are indicated. This output is not to be read on its own but mostly needed by the following function, that integrates it with the output of *analysis_gf_sol* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = cons_prod_dict('./pipeline/inputs/ecoli_tutorial2.csv', model, universal, consumption, production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the printed output\n",
    "\n",
    "Most of what is preinted is related to the thermodynamic analysis. This output is the most comprehensive one and is structured with nested python dictionaries. Every solution of *analysis_gf_sol* is indicated as with the key consumption following by the number of the round of iteration of gapfilling (with the fluxes of consumption of the substrate). The respective production key reports the results of *dict_prod_sol* analysis (i.e. the fluxes of production of the target) and the result of the thermodynamic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scores_output = scores_evaluations('./pipeline/inputs/ecoli_tutorial2.csv', consumption, final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# production itacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "\n",
    "from pipeline.scripts.import_models import get_universal_main, get_reference_model\n",
    "from pipeline.scripts.input_parser import main\n",
    "from pipeline.scripts.analysis import analysis_gf_sol, dict_prod_sol, cons_prod_dict\n",
    "from pipeline.scripts.import_models import get_universal_main, get_reference_model\n",
    "from pipeline.scripts.input_parser import main\n",
    "from pipeline.scripts.scoring_system import (scores_evaluations, score_BB_presence, \n",
    "                            plotting_KI_BB_scores)\n",
    "from pipeline.scripts.to_and_from_biobrick_wikidata import (output_for_biobrick_search, \\\n",
    "                                        run_harmonization_per_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_repo = \"./pipeline/inputs\"\n",
    "model3 = get_reference_model(data_repo, './pipeline/inputs/ecoli_tutorial3.csv')\n",
    "universal3 = get_universal_main(data_repo, './pipeline/inputs/ecoli_tutorial3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('./pipeline/inputs/ecoli_tutorial2.csv', universal3, model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printed output above can be unserstood better looking at the example input file *ecoli_tutorial2.csv* that can be found in the inputs directory. \n",
    " \n",
    "* There is not transporter of methane in E. coli model iML1515. Thus, the pipeline adds the reaction included in the input file \n",
    "* Formate, intermediate product of methane oxidation is indicated as target\n",
    "* ALCD1 reaction (methanole dehydrogenase) is already in the model, so the pipeline recognize it and does not add it to the universal\n",
    "* There are no methane oxidizing reactions in the BiGG database, therefore the pipeline adds them to the universal reaction model.\n",
    "\n",
    "![input_main](./formate.png)\n",
    "\n",
    "\n",
    "## Running the analysis for making the model able to grow on the indicated substrate\n",
    "\n",
    "In this case the objective is to have an *E. coli* strain able to grow on methane. The chassis can't naturally grow on methane, therefore it is expected that the pipeline will use gapfilling to serach for additional reactions. The search can take few hours, depending on the PC, the number of iteration and the type of reactions needed. For this analysis on a Windows AMD64 processor running the pipeline via Jupyter notebook it takes apporximately 4 hours.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption3 = analysis_gf_sol('./pipeline/inputs/ecoli_tutorial3.csv', model3, universal3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the printed output\n",
    "\n",
    "The output reports several information relative to the set up of the analysis as introduced above (e.g. constraints) and the results of the analysis with gapfilling. In order from top to bottom you can find the following information:\n",
    "\n",
    "- The biomass upper bound to the growth rate of the wild type (0.87 1/h)\n",
    "- Indication of the fluxes of the compounds that are take up from the mediume by the wild type strain\n",
    "- The old and new bounds of the exchange reaction of the compounds indicated by the user \n",
    "- The result of the analysis start after the indication that GapFilling algorithm is being run.  \n",
    "- The analysis of gapfilling can be run in several iteration (each one looking for reactions that if added satisfy the model's objective, growth in this case). The result of each iteration starts with a number. \n",
    "\n",
    "This function also generate an intermediate .csv file that can be found in the pipeline/outputs folder. It is advicable to rename the file before running *analysis_gf_sol* further, otherwise it get overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production3 = dict_prod_sol('./pipeline/inputs/ecoli_tutorial3.csv', consumption3, model3, universal3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the printed output\n",
    "\n",
    "since the model can already produce formate, gapfilling analysis is not run and thus the analysis is way faster and the production rates are indicated. This output is not to be read on its own but mostly needed by the following function, that integrates it with the output of *analysis_gf_sol* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final3 = cons_prod_dict('./pipeline/inputs/ecoli_tutorial3.csv', model3, universal3, consumption3, production3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the printed output\n",
    "\n",
    "Most of what is preinted is related to the thermodynamic analysis. This output is the most comprehensive one and is structured with nested python dictionaries. Every solution of *analysis_gf_sol* is indicated as with the key consumption following by the number of the round of iteration of gapfilling (with the fluxes of consumption of the substrate). The respective production key reports the results of *dict_prod_sol* analysis (i.e. the fluxes of production of the target) and the result of the thermodynamic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_output3 = scores_evaluations('./pipeline/inputs/ecoli_tutorial3.csv', consumption3, final3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "1. A. Ebrahim, J. A. Lerman, B. O. Palsson, and D. R. Hyduke, “COBRApy: COnstraints-Based Reconstruction and Analysis for Python,” BMC Syst. Biol., vol. 7, no. 1, p. 74, Aug. 2013, doi: 10.1186/1752-0509-7-74."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
